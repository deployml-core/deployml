{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"deployml","text":"<p>Welcome to deployml, a python library for deploying an end-to-end machine learning operations (MLOps) infrastructure in the cloud.</p>"},{"location":"#why-was-deployml-created","title":"Why was deployml created?","text":"<p>deployml was born out of the frustrations of teaching an MLOps course. Understanding the general concepts of MLOps is easy enough through lectures and case studies, but students wanted hands-on experience, and preferably on a truly scalable infrastructure. As I went about designing labs and homework assignments to give students what they want - the opportunity to work with ML end-to-end in the cloud - I quickly noticed a problem: many students were spending hours on just getting things to work. I wanted to create a tool that could facilitate the learning of the MLOps pipeline and processes, and with the help of some very dedicated graduate students, deployml is the tool we came up with. </p> <p>The ultimate goal of deployml is to make the infrastructure part just a little bit easier so that more time can be spent on actually using the infrastructure to practice with developing, deploying, and monitoring machine learning models. </p> <p>We recognize that there is a lot that can be learned by struggling with getting infrastructure to work - but we've noticed that when students spend what precious time they have simply getting it to work, they have no fuel left to explore the different stages of the MLOps pipeline. We hope that this tool gives them that freedom, while at the same time, gives students the flexibility to practice with docker, kubernetes, terraform, and cloud computing, which are essential tools for working in MLOps. </p>"},{"location":"#who-is-deployml-for","title":"Who is deployml for?","text":"<p>deployml was created for instructors and students of MLOps. It was not designed to be used by companies seeking a tool for MLOps infrastructure. </p>"},{"location":"#what-does-deployml-do","title":"What does deployml do?","text":"<p>deployml will provision the infrastructure needed for a basic end-to-end MLOps pipeline in Google Cloud Platform, which includes the following components:</p> <ul> <li>experiment tracking  </li> <li>model and artifact tracking and model registration  </li> <li>feature store   </li> <li>ML pipelines (e.g. training and scoring pipelines)  </li> <li>online and offline model deployment  </li> <li>model monitoring  </li> </ul> <p>What is currently not included in the pipeline is:</p> <ul> <li>anything to do with LLMs and generative AI  </li> <li>scalable model development  </li> <li>data versioning and data pipelines    </li> </ul> <p>In future releases, we hope to extend deployml to AWS, and make more open source tools available for the different components.</p>"},{"location":"contributing/","title":"Contributing to deployml","text":"<p>We welcome contributors who are interested in helping with issues/bugs and expanding and improving upon what has already been built. Please note that since this is an academic project that is supervised by one faculty member, and maintained by students, it is not always possible to respond promptly to messages.</p>"},{"location":"contributing/#ways-to-contribute","title":"Ways to Contribute","text":"<p>You can help improve the project in several ways:</p> <ul> <li>Bug reports: Identify issues with deployment, configuration, or documentation (open an issue).  </li> <li>Feature requests: Suggest improvements that would benefit classroom use or learning (open an issue).  </li> <li>Code contributions: Add features, fix bugs, or improve reliability (submit a pull request).  </li> <li>Documentation: Improve setup guides, examples, or explanations for students and instructors (submit a pull request).  </li> <li>Educational feedback: Share insights about how the tool works in a teaching or learning context (contact info here).</li> </ul>"},{"location":"contributing/#getting-started-with-code-or-documentation-contributions","title":"Getting Started with Code or Documentation Contributions","text":"<ol> <li>Fork the repository and clone your fork locally.  </li> <li>Follow the setup instructions in the main README to install dependencies and configure your environment.  </li> <li>Create a new branch for your work with a descriptive name (e.g., fix-deployment-logging or add-example-yaml).</li> </ol>"},{"location":"contributing/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<ol> <li>Push your changes to your fork.  </li> <li>Open a pull request against the main branch.  </li> <li>In the pull request description, briefly explain:  <ul> <li>What the change does. </li> <li>Why it is needed. </li> <li>How it was tested.</li> </ul> </li> </ol> <p>Pull requests may be reviewed with an emphasis on clarity, maintainability, and suitability for classroom use.</p>"},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":"<p>If you find a bug or have a suggestion, please open an issue and include:</p> <ul> <li>A clear description of the problem or idea. </li> <li>Steps to reproduce (if applicable). </li> <li>Relevant logs, error messages, or screenshots.</li> </ul>"},{"location":"contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>All contributors are expected to engage respectfully and constructively. This project follows a standard open-source code of conduct: be inclusive, be professional, and assume good intent.</p>"},{"location":"installation/","title":"Installation Guide","text":""},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before installing deployml, ensure you have:</p> <ul> <li>Python 3.8+</li> <li>Docker (for building container images)</li> <li>Cloud CLI tools (gcloud for GCP, aws-cli for AWS)</li> <li>Terraform (for infrastructure provisioning)</li> <li>kubectl (for Kubernetes deployments)</li> </ul>"},{"location":"installation/#install-deployml","title":"Install deployml","text":""},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code>pip install deployml-core\n</code></pre>"},{"location":"installation/#from-source","title":"From source","text":"<pre><code>git clone https://github.com/deployml-core/deployml.git\ncd deployml\npip install -e .\n</code></pre>"},{"location":"installation/#verify-installation","title":"Verify Installation","text":"<pre><code># Check version\ndeployml --version\n</code></pre> <p>Check that you have the right dependencies. <pre><code># Run system checks\ndeployml doctor --project-id YOUR_PROJECT_ID\n</code></pre></p>"},{"location":"installation/#quick-start","title":"Quick Start","text":"<pre><code># Initialize GCP project\ndeployml init --provider gcp --project-id YOUR_PROJECT_ID\n\n# Generate a sample config\ndeployml generate\n\n# Deploy your stack\ndeployml deploy --config-path your-config.yaml\n</code></pre>"},{"location":"api/cli-commands/","title":"CLI Commands Reference","text":"<p>Complete reference for all deployml CLI commands.</p>"},{"location":"api/cli-commands/#core-commands","title":"Core Commands","text":""},{"location":"api/cli-commands/#deployml-deploy","title":"<code>deployml deploy</code>","text":"<p>Deploy infrastructure based on a YAML configuration file.</p> <p>Usage:</p> <pre><code># Basic usage\ndeployml deploy --config-path config.yaml\n\n# Skip confirmation prompts\ndeployml deploy --config-path config.yaml --yes\n\n# Generate manifests only (GKE)\ndeployml deploy --config-path config.yaml --generate-only\n</code></pre> <p>Options: - <code>--config-path</code>, <code>-c</code>: Path to YAML config file (required) - <code>--yes</code>, <code>-y</code>: Skip confirmation prompts - <code>--generate-only</code>, <code>-g</code>: Only generate manifests, do not apply (GKE)</p> <p>Example:</p> <pre><code># Deploy Cloud Run stack\ndeployml deploy -c cloud-run-config.yaml\n\n# Deploy GKE stack with manifest generation only\ndeployml deploy -c gke-config.yaml --generate-only\n</code></pre>"},{"location":"api/cli-commands/#deployml-destroy","title":"<code>deployml destroy</code>","text":"<p>Destroy infrastructure and optionally clean up workspace.</p> <p>Usage:</p> <pre><code># Destroy infrastructure\ndeployml destroy --config-path config.yaml\n\n# Clean workspace after destroy\ndeployml destroy --config-path config.yaml --clean-workspace\n\n# Skip confirmation\ndeployml destroy --config-path config.yaml --yes\n</code></pre> <p>Options: - <code>--config-path</code>, <code>-c</code>: Path to YAML config file (required) - <code>--workspace</code>: Override workspace name from config - <code>--clean-workspace</code>: Remove entire workspace after destroy - <code>--yes</code>, <code>-y</code>: Skip confirmation prompts</p> <p>Example:</p> <pre><code># Destroy and clean workspace\ndeployml destroy -c config.yaml --clean-workspace --yes\n</code></pre>"},{"location":"api/cli-commands/#deployml-init","title":"<code>deployml init</code>","text":"<p>Initialize cloud project by enabling required APIs.</p> <p>Usage:</p> <pre><code># Initialize GCP project\ndeployml init --provider gcp --project-id YOUR_PROJECT_ID\n\n# Initialize AWS project\ndeployml init --provider aws\n</code></pre> <p>Options: - <code>--provider</code>, <code>-p</code>: Cloud provider (gcp, aws, azure) - <code>--project-id</code>, <code>-j</code>: Project ID (for GCP)</p> <p>Example:</p> <pre><code>deployml init -p gcp -j my-project-id\n</code></pre>"},{"location":"api/cli-commands/#deployml-generate","title":"<code>deployml generate</code>","text":"<p>Generate a deployment configuration YAML file interactively.</p> <p>Usage:</p> <pre><code>deployml generate\n</code></pre> <p>Example:</p> <pre><code># Interactive config generation\ndeployml generate\n# Follow prompts to create config.yaml\n</code></pre>"},{"location":"api/cli-commands/#deployml-doctor","title":"<code>deployml doctor</code>","text":"<p>Run system checks for required tools and authentication.</p> <p>Usage:</p> <pre><code># Basic check\ndeployml doctor\n\n# Check GCP APIs\ndeployml doctor --project-id YOUR_PROJECT_ID\n</code></pre> <p>Options: - <code>--project-id</code>, <code>-j</code>: Project ID (for GCP API checks)</p> <p>Example:</p> <pre><code>deployml doctor --project-id my-project-id\n</code></pre>"},{"location":"api/cli-commands/#gke-commands","title":"GKE Commands","text":""},{"location":"api/cli-commands/#deployml-gke-init","title":"<code>deployml gke-init</code>","text":"<p>Generate Kubernetes manifests for GKE.</p> <p>Usage:</p> <pre><code># Generate MLflow manifests\ndeployml gke-init \\\n  --output-dir ./manifests/mlflow \\\n  --image mlflow-demo:latest \\\n  --project YOUR_PROJECT_ID \\\n  --service mlflow\n\n# Generate FastAPI manifests\ndeployml gke-init \\\n  --output-dir ./manifests/fastapi \\\n  --image fastapi-demo:latest \\\n  --project YOUR_PROJECT_ID \\\n  --service fastapi \\\n  --mlflow-uri http://mlflow-service:5000\n</code></pre> <p>Options: - <code>--output-dir</code>, <code>-o</code>: Directory to create Kubernetes manifests (required) - <code>--image</code>, <code>-i</code>: Docker image name (local or GCR) (required) - <code>--project</code>, <code>-p</code>: GCP project ID (required) - <code>--service</code>, <code>-s</code>: Service type: mlflow or fastapi (default: mlflow) - <code>--mlflow-uri</code>, <code>-m</code>: MLflow URI (for FastAPI)</p> <p>Example:</p> <pre><code>deployml gke-init \\\n  -o ./manifests/mlflow \\\n  -i mlflow-demo:latest \\\n  -p my-project-id \\\n  -s mlflow\n</code></pre>"},{"location":"api/cli-commands/#deployml-gke-deploy","title":"<code>deployml gke-deploy</code>","text":"<p>Deploy Kubernetes manifests to GKE cluster.</p> <p>Usage:</p> <pre><code>deployml gke-deploy \\\n  --manifest-dir ./manifests/mlflow \\\n  --cluster my-gke-cluster \\\n  --project YOUR_PROJECT_ID \\\n  --zone us-west1-a\n</code></pre> <p>Options: - <code>--manifest-dir</code>, <code>-d</code>: Directory containing deployment.yaml and service.yaml (required) - <code>--cluster</code>, <code>-c</code>: GKE cluster name (required) - <code>--project</code>, <code>-p</code>: GCP project ID (required) - <code>--zone</code>, <code>-z</code>: GKE cluster zone - <code>--region</code>, <code>-r</code>: GKE cluster region</p> <p>Example:</p> <pre><code>deployml gke-deploy \\\n  -d ./manifests/mlflow \\\n  -c my-cluster \\\n  -p my-project-id \\\n  -z us-west1-a\n</code></pre>"},{"location":"api/cli-commands/#deployml-gke-apply","title":"<code>deployml gke-apply</code>","text":"<p>Apply previously generated manifests to GKE cluster.</p> <p>Usage:</p> <pre><code>deployml gke-apply --config-path gke-config.yaml\n</code></pre> <p>Options: - <code>--config-path</code>, <code>-c</code>: Path to YAML config file (required) - <code>--yes</code>, <code>-y</code>: Skip confirmation prompts</p> <p>Example:</p> <pre><code># Apply manifests after editing\ndeployml gke-apply -c gke-config.yaml\n</code></pre>"},{"location":"api/cli-commands/#minikube-commands","title":"Minikube Commands","text":""},{"location":"api/cli-commands/#deployml-minikube-init","title":"<code>deployml minikube-init</code>","text":"<p>Initialize minikube and generate FastAPI Kubernetes manifests.</p> <p>Usage:</p> <pre><code>deployml minikube-init \\\n  --output-dir ./manifests/fastapi \\\n  --image fastapi-demo:latest \\\n  --mlflow-uri http://mlflow-service:5000\n</code></pre> <p>Options: - <code>--output-dir</code>, <code>-o</code>: Directory to create Kubernetes manifests (required) - <code>--image</code>, <code>-i</code>: FastAPI Docker image (required) - <code>--mlflow-uri</code>, <code>-m</code>: MLflow tracking URI (optional) - <code>--start-cluster</code>: Start minikube cluster if not running (default: true)</p> <p>Example:</p> <pre><code>deployml minikube-init \\\n  -o ./manifests/fastapi \\\n  -i fastapi-demo:latest \\\n  -m http://mlflow-service:5000\n</code></pre>"},{"location":"api/cli-commands/#deployml-minikube-deploy","title":"<code>deployml minikube-deploy</code>","text":"<p>Deploy FastAPI to minikube using kubectl apply.</p> <p>Usage:</p> <pre><code>deployml minikube-deploy --manifest-dir ./manifests/fastapi\n</code></pre> <p>Options: - <code>--manifest-dir</code>, <code>-d</code>: Directory containing deployment.yaml and service.yaml (required) - <code>--image-name</code>, <code>-i</code>: Docker image name to load into minikube (auto-detected if not provided)</p> <p>Example:</p> <pre><code>deployml minikube-deploy -d ./manifests/fastapi\n</code></pre>"},{"location":"api/cli-commands/#deployml-mlflow-init","title":"<code>deployml mlflow-init</code>","text":"<p>Initialize minikube and generate MLflow Kubernetes manifests.</p> <p>Usage:</p> <pre><code>deployml mlflow-init \\\n  --output-dir ./manifests/mlflow \\\n  --image mlflow-demo:latest \\\n  --backend-store-uri sqlite:///mlflow.db\n</code></pre> <p>Options: - <code>--output-dir</code>, <code>-o</code>: Directory to create Kubernetes manifests (required) - <code>--image</code>, <code>-i</code>: MLflow Docker image (required) - <code>--backend-store-uri</code>, <code>-b</code>: Backend store URI (defaults to SQLite) - <code>--artifact-root</code>, <code>-a</code>: Artifact root path (defaults to /mlflow-artifacts) - <code>--start-cluster</code>: Start minikube cluster if not running (default: true)</p> <p>Example:</p> <pre><code>deployml mlflow-init \\\n  -o ./manifests/mlflow \\\n  -i mlflow-demo:latest \\\n  -b sqlite:///mlflow.db\n</code></pre>"},{"location":"api/cli-commands/#deployml-mlflow-deploy","title":"<code>deployml mlflow-deploy</code>","text":"<p>Deploy MLflow to minikube using kubectl apply.</p> <p>Usage:</p> <pre><code>deployml mlflow-deploy --manifest-dir ./manifests/mlflow\n</code></pre> <p>Options: - <code>--manifest-dir</code>, <code>-d</code>: Directory containing deployment.yaml and service.yaml (required) - <code>--image-name</code>, <code>-i</code>: Docker image name to load into minikube (auto-detected if not provided)</p> <p>Example:</p> <pre><code>deployml mlflow-deploy -d ./manifests/mlflow\n</code></pre>"},{"location":"api/cli-commands/#teardown-commands","title":"Teardown Commands","text":""},{"location":"api/cli-commands/#deployml-teardown","title":"<code>deployml teardown</code>","text":"<p>Manage auto-teardown: cancel, status, update, or schedule.</p> <p>Usage:</p> <pre><code># Cancel scheduled teardown\ndeployml teardown cancel --config-path config.yaml\n\n# Check teardown status\ndeployml teardown status --config-path config.yaml\n\n# Update teardown schedule\ndeployml teardown update --config-path config.yaml\n\n# Schedule new teardown\ndeployml teardown schedule --config-path config.yaml\n</code></pre> <p>Options: - <code>--config-path</code>, <code>-c</code>: Path to YAML config file (required)</p> <p>Example:</p> <pre><code># Check teardown status\ndeployml teardown status -c config.yaml\n\n# Cancel teardown\ndeployml teardown cancel -c config.yaml\n</code></pre>"},{"location":"api/cli-commands/#complete-examples","title":"Complete Examples","text":""},{"location":"api/cli-commands/#complete-gke-deployment","title":"Complete GKE Deployment","text":"<pre><code># 1. Generate manifests\ndeployml deploy --config-path gke-config.yaml --generate-only\n\n# 2. Review manifests\nls -la .deployml/gke-mlflow-fastapi/manifests/\n\n# 3. Apply manifests\ndeployml gke-apply --config-path gke-config.yaml\n</code></pre>"},{"location":"api/cli-commands/#cloud-run-with-auto-teardown","title":"Cloud Run with Auto-Teardown","text":"<pre><code># Deploy with 24-hour auto-teardown\ndeployml deploy --config-path cloud-run-config.yaml\n\n# Check teardown status\ndeployml teardown status --config-path cloud-run-config.yaml\n\n# Cancel teardown\ndeployml teardown cancel --config-path cloud-run-config.yaml\n</code></pre>"},{"location":"api/cli-commands/#minikube-local-development","title":"Minikube Local Development","text":"<pre><code># 1. Start minikube\nminikube start\n\n# 2. Generate MLflow manifests\ndeployml mlflow-init -o ./manifests/mlflow -i mlflow-demo:latest\n\n# 3. Deploy MLflow\ndeployml mlflow-deploy -d ./manifests/mlflow\n\n# 4. Generate FastAPI manifests\ndeployml minikube-init -o ./manifests/fastapi -i fastapi-demo:latest -m http://mlflow-service:5000\n\n# 5. Deploy FastAPI\ndeployml minikube-deploy -d ./manifests/fastapi\n</code></pre>"},{"location":"api/cli-commands/#next-steps","title":"Next Steps","text":"<ul> <li>Read Installation Guide</li> <li>Explore Tutorials</li> </ul>"},{"location":"api/overview/","title":"API Reference Overview","text":"<p>deployml provides a command-line interface (CLI) for deploying and managing MLOps infrastructure. This section documents all available commands and their usage.</p>"},{"location":"api/overview/#command-categories","title":"Command Categories","text":""},{"location":"api/overview/#core-commands","title":"Core Commands","text":"<p>Core commands handle the primary deployment workflow. </p> <ul> <li>The <code>deploy</code> command provisions infrastructure based on your YAML configuration file.  </li> <li>The <code>destroy</code> command tears down infrastructure and optionally cleans up workspace files.  </li> <li>The <code>init</code> command initializes your cloud project by enabling required APIs.  </li> <li>The <code>generate</code> command creates a deployment configuration interactively.  </li> <li>The <code>doctor</code> command runs system checks to verify required tools and authentication.</li> </ul>"},{"location":"api/overview/#deployment-commands","title":"Deployment Commands","text":"<p>Deployment-specific commands support different deployment types.  </p> <ul> <li>GKE commands handle Kubernetes deployments with a two-step workflow: generate manifests, then apply them.  </li> <li>Minikube commands support local development and testing.  </li> <li>MLflow-specific commands simplify MLflow deployment workflows.</li> </ul>"},{"location":"api/overview/#management-commands","title":"Management Commands","text":"<p>Management commands help you control deployed infrastructure. Teardown commands manage automatic infrastructure destruction, allowing you to schedule, cancel, check status, and update teardown schedules.</p>"},{"location":"api/overview/#getting-started","title":"Getting Started","text":"<p>To get started with deployml commands:  </p> <ul> <li>First install deployml.  </li> <li>Run the doctor command to verify your setup.  </li> <li>Then use the generate command to create a configuration file, or create one manually. </li> <li>Finally, use the deploy command to provision your infrastructure.</li> </ul> <p>For detailed command documentation, see the CLI Commands reference.</p>"},{"location":"api/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Explore CLI Commands for complete command reference</li> <li>Check Installation Guide for setup instructions</li> <li>Review Tutorials for step-by-step guides</li> </ul>"},{"location":"features/costs/","title":"Cost Estimates","text":"<p>deployml integrates with Infracost to provide cost estimates before deploying your infrastructure, helping you manage cloud costs effectively in academic settings.</p>"},{"location":"features/costs/#overview","title":"Overview","text":"<p>Cost analysis runs automatically during deployment, showing monthly cost estimates for your entire stack, cost breakdowns by component, and warnings if costs exceed your configured threshold. The process analyzes your Terraform configuration before deployment, allowing you to adjust your configuration based on estimates.</p>"},{"location":"features/costs/#setup","title":"Setup","text":"<p>Install Infracost and register for a free API key using the instructions here. </p>"},{"location":"features/costs/#configuration","title":"Configuration","text":"<p>Cost analysis is enabled by default. Configure it in your YAML file to enable or disable cost analysis, set a warning threshold in USD (default $100/month), and choose the currency for cost display.</p> <p>Here is an example of what this might look like: <pre><code>cost_analysis:\n  enabled: true              # Enable/disable cost analysis (default: true)\n  warning_threshold: 50.0    # Warn if monthly cost exceeds this amount (default: 100.0)\n  currency: \"USD\"   \n  bucket_amount: 200        # GB stored across GCS buckets\n  cloudsql_amount: 50       # GB of Cloud SQL storage\n</code></pre></p>"},{"location":"features/costs/#typical-costs","title":"Typical Costs","text":"<p>Here are estimated typical costs for several GCP services, but please do not simply believe these numbers without keeping track of costs yourself.</p> <ul> <li>Cloud Run services cost $10-30 per month depending on traffic.  </li> <li>Cloud SQL PostgreSQL ranges from $7/month for small instances to $25+ for production.  </li> <li>Google Cloud Storage costs approximately $0.020 per GB per month.   </li> <li>BigQuery storage costs $0.020 per GB per month with query costs based on data scanned.  </li> <li>Cloud VMs cost approximately $25 per month for medium instances.   </li> <li>GKE clusters have no management fee, but you pay for VM instances and load balancers. Note that the GKE can get very expensive very quickly.</li> </ul>"},{"location":"features/costs/#cost-optimization","title":"Cost Optimization","text":"<p>Here are some tips to keep the costs low while you are learning:  </p> <ul> <li>Use SQLite instead of Cloud SQL whenever possible, particularly for development purposes and when your data is small.  </li> <li>Enable auto-teardown to prevent forgotten deployments. </li> <li>Use Cloud Run for variable workloads to take advantage of scale-to-zero pricing.</li> </ul>"},{"location":"features/overview/","title":"Features Overview","text":"<p>deployml is a Python library designed to simplify the deployment of end-to-end MLOps infrastructure in the cloud. Built specifically for academia, deployml enables instructors and students to focus on learning MLOps concepts rather than struggling with infrastructure setup.</p>"},{"location":"features/overview/#core-capabilities","title":"Core Capabilities","text":""},{"location":"features/overview/#infrastructure-as-code","title":"Infrastructure as Code","text":"<p>deployml uses Terraform to provision cloud infrastructure declaratively. Instead of manually configuring services through cloud consoles, you define your entire MLOps stack in a simple YAML configuration file. This approach provides several key benefits: reproducible deployments that work consistently across environments, version-controlled infrastructure that can be tracked in Git, easy teardown and cleanup when projects are complete, and elimination of manual configuration errors.</p>"},{"location":"features/overview/#cost-analysis","title":"Cost Analysis","text":"<p>Understanding cloud costs before deployment is crucial, especially in academic settings with limited budgets. deployml integrates with Infracost to provide cost estimates before any infrastructure is provisioned. You'll see monthly cost projections for your entire stack, receive warnings if costs exceed your configured threshold, and get cost breakdowns by component. This helps prevent unexpected bills and allows for better budget planning.</p>"},{"location":"features/overview/#multi-cloud-support","title":"Multi-Cloud Support","text":"<p>Currently focused on Google Cloud Platform (GCP), deployml supports multiple deployment types to match different use cases. Cloud Run provides serverless, auto-scaling container deployments ideal for APIs and services with variable traffic. Google Kubernetes Engine (GKE) offers Kubernetes deployments with full control over cluster configuration. Cloud VM enables persistent virtual machine deployments for long-running services that need stable storage. Minikube support allows for local development and testing without any cloud costs.</p>"},{"location":"features/overview/#ml-focused-components","title":"ML-Focused Components","text":"<p>deployml comes pre-configured with essential MLOps tools that work together seamlessly. The platform supports experiment tracking through MLflow, allowing you to log parameters, metrics, and artifacts from your ML experiments. Model registry capabilities enable centralized model versioning and stage management. Feature store integration with Feast provides consistent features across training and serving. FastAPI endpoints make it easy to deploy models as production-ready APIs. Grafana dashboards offer monitoring and visualization capabilities. Workflow orchestration through cron jobs enables scheduled training, scoring, and monitoring tasks.</p>"},{"location":"features/overview/#what-deployml-provides","title":"What deployml Provides","text":"<p>deployml provisions infrastructure for a complete MLOps pipeline covering all major stages of the machine learning lifecycle:  </p> <ul> <li>Experiment tracking allows you to track ML experiments and compare results across different runs.   </li> <li>Artifact tracking stores and versions model artifacts, datasets, and other ML assets.  </li> <li>Model registry provides centralized model versioning and management with stage transitions.   </li> <li>Feature store manages features for both training and serving with consistency guarantees.   </li> <li>Online model serving deploys models as API endpoints that can be integrated into applications.  </li> <li>Offline model serving deploys models using an orchestration engine.  </li> <li>Model monitoring tracks model performance, drift, and system health.   </li> <li>Workflow orchestration schedules and runs training and scoring jobs automatically.</li> </ul>"},{"location":"features/overview/#whats-not-included","title":"What's Not Included","text":"<p>deployml focuses on traditional ML workflows and does not include tooling for LLMs and generative AI, scalable model development frameworks, or data versioning and data pipelines. These areas may be added in future releases based on community needs.</p>"},{"location":"features/overview/#use-cases","title":"Use Cases","text":""},{"location":"features/overview/#for-instructors","title":"For Instructors","text":"<p>Instructors teaching MLOps courses can use deployml to quickly set up lab environments for students, demonstrate MLOps concepts with real infrastructure, manage costs effectively with auto-teardown features, and provide reproducible deployment examples that students can follow.</p>"},{"location":"features/overview/#for-students","title":"For Students","text":"<p>Students learning MLOps can use deployml to gain hands-on experience without getting bogged down in infrastructure complexity, practice with production-like environments, understand cloud deployment patterns, and focus their time on ML workflows rather than infrastructure setup.</p>"},{"location":"features/pipeline/","title":"MLOps Components","text":"<p>deployml provisions a complete end-to-end MLOps pipeline with pre-configured components. Each component can be enabled or disabled based on your specific needs, allowing you to build a stack that matches your learning objectives or project requirements.</p>"},{"location":"features/pipeline/#component-overview","title":"Component Overview","text":"<p>The deployml stack consists of six main stages that work together to provide a complete MLOps solution. Experiment tracking enables you to track and compare ML experiments with detailed logging of parameters, metrics, and results. Artifact tracking stores model artifacts, datasets, and other ML assets in versioned cloud storage. Model registry provides centralized model versioning and management with stage transitions from development to production. Model serving deploys models as production-ready API endpoints that can be integrated into applications. Model monitoring tracks model performance, detects drift, and monitors system health. Workflow orchestration schedules and runs training, scoring, and monitoring jobs automatically.</p>"},{"location":"features/pipeline/#experiment-tracking","title":"Experiment Tracking","text":"<p>Experiment tracking is fundamental to MLOps, allowing you to log, compare, and reproduce ML experiments. deployml supports MLflow as the experiment tracking solution.</p> <p>MLflow provides comprehensive experiment tracking capabilities. You can track experiments with automatic logging of parameters, metrics, and artifacts. The MLflow UI offers visual comparison of runs, making it easy to identify the best performing models. Integration with artifact storage ensures all experiment data is preserved. MLflow supports multiple backend stores including PostgreSQL for production deployments and SQLite for development environments.</p>"},{"location":"features/pipeline/#artifact-tracking","title":"Artifact Tracking","text":"<p>Model artifacts, datasets, and other ML assets need to be stored securely and versioned properly. deployml integrates artifact tracking with experiment tracking, ensuring that all artifacts from your experiments are automatically stored and versioned.</p> <p>Artifacts are stored in Google Cloud Storage buckets with automatic bucket creation and permission management. You can configure custom bucket names or let deployml generate unique names automatically. All artifacts are versioned, allowing you to track changes over time and retrieve specific versions when needed.</p>"},{"location":"features/pipeline/#model-registry","title":"Model Registry","text":"<p>The model registry provides centralized model versioning and management. Once models are trained and evaluated, they can be registered in the model registry with metadata, tags, and version information. Models can be promoted through stages from development to staging to production, with clear lineage tracking showing which experiment produced each model version.</p> <p>The registry integrates seamlessly with experiment tracking, allowing you to register models directly from experiments. Model serving components can pull models from the registry, ensuring that production deployments always use the correct model version.</p>"},{"location":"features/pipeline/#model-serving","title":"Model Serving","text":"<p>Once models are trained and registered, they need to be deployed as production-ready APIs. deployml supports FastAPI for model serving, providing RESTful API endpoints with automatic OpenAPI documentation.</p> <p>FastAPI services can be deployed on Cloud Run for serverless, auto-scaling deployments, on GKE for Kubernetes-based production deployments, or on Cloud VMs for persistent deployments. The serving endpoints integrate with the model registry, allowing you to specify which model version to serve. Health check endpoints ensure services are running correctly, and metrics endpoints provide observability into service performance.</p>"},{"location":"features/pipeline/#model-monitoring","title":"Model Monitoring","text":"<p>Model monitoring is essential for maintaining model performance in production. deployml supports Grafana for monitoring dashboards, allowing you to visualize model performance metrics, prediction latency, request rates, error rates, and system health.</p> <p>Additional monitoring capabilities include explainability monitoring to track model explainability metrics and feature importance over time, and fairness monitoring to detect bias and ensure models meet fairness requirements. These monitoring tools help identify model drift, performance degradation, and data quality issues before they impact production systems.</p>"},{"location":"features/pipeline/#workflow-orchestration","title":"Workflow Orchestration","text":"<p>MLOps pipelines often require scheduled tasks such as periodic model retraining, batch scoring, and monitoring report generation. deployml supports workflow orchestration through cron jobs that can be scheduled to run at specific intervals.</p> <p>Cron jobs can be configured to run training pipelines, perform batch scoring on large datasets, validate data quality, generate monitoring reports, and perform other periodic tasks. These jobs run as Cloud Run services, providing serverless execution with automatic scaling and cost-effective operation.</p> <p>Offline scoring capabilities allow you to run batch prediction jobs on large datasets, making it easy to score historical data or generate predictions for large batches without real-time API calls.</p>"},{"location":"features/pipeline/#component-integration","title":"Component Integration","text":"<p>All components in the deployml stack are designed to work together seamlessly. Experiment tracking feeds into the model registry, which provides models to serving endpoints. Model monitoring tracks the performance of deployed models, and workflow orchestration automates the entire pipeline from training to deployment to monitoring.</p> <p>This integrated approach means you can focus on building and improving your ML models rather than managing the infrastructure that connects these components together.</p>"},{"location":"features/pipeline/#database-backends","title":"Database Backends","text":"<p>deployml supports multiple database backends to match different deployment scenarios. PostgreSQL through Cloud SQL provides a production-ready database solution suitable for multi-user deployments, scalable storage needs, and production environments. SQLite offers a lightweight alternative perfect for development, single-user deployments, and cost-effective small projects.</p> <p>Components that use databases include MLflow for experiment tracking and model registry, and any custom components you might deploy.</p>"},{"location":"features/pipeline/#storage-options","title":"Storage Options","text":"<p>Storage is a critical component of any MLOps pipeline. Google Cloud Storage provides durable, scalable storage for MLflow artifacts, model files, and datasets.</p>"},{"location":"tutorials/gcp-cloud-run/","title":"GCP Cloud Run Deployment","text":"<p>Deploy MLflow and FastAPI to Google Cloud Run using deployml.</p>"},{"location":"tutorials/gcp-cloud-run/#overview","title":"Overview","text":"<p>Cloud Run is a serverless container platform that automatically scales your applications. It's ideal for:</p> <ul> <li>Automatic scaling</li> <li>Pay per use</li> <li>No infrastructure management</li> <li>Fast deployment</li> </ul>"},{"location":"tutorials/gcp-cloud-run/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/gcp-cloud-run/#1-create-configuration-file","title":"1. Create Configuration File","text":"<p>Create <code>cloud-run-config.yaml</code>:</p> <pre><code>name: mlflow-cloud-run\nprovider:\n  name: gcp\n  project_id: YOUR_PROJECT_ID\n  region: us-west1\n\ndeployment:\n  type: cloud_run\n\nstack:\n  - experiment_tracking:\n      name: mlflow\n      params:\n        service_name: mlflow-server\n        allow_public_access: true\n\n  - artifact_tracking:\n      name: mlflow\n      params:\n        artifact_bucket: mlflow-artifacts-bucket\n        create_artifact_bucket: true\n\n  - model_registry:\n      name: mlflow\n      params:\n        backend_store_uri: sqlite:///mlflow.db\n\n  - model_serving:\n      name: fastapi\n      params:\n        service_name: fastapi-server\n        mlflow_tracking_uri: http://mlflow-server:8080\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#2-initialize-gcp-project","title":"2. Initialize GCP Project","text":"<pre><code># Initialize GCP project (first time only)\ndeployml init --provider gcp --project-id YOUR_PROJECT_ID\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#3-deploy","title":"3. Deploy","text":"<pre><code># Deploy stack\ndeployml deploy --config-path cloud-run-config.yaml\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#4-access-services","title":"4. Access Services","text":"<p>After deployment, you'll see URLs like:</p> <pre><code>MLflow URL: https://mlflow-server-xxxxx-uw.a.run.app\nFastAPI URL: https://fastapi-server-xxxxx-uw.a.run.app\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#configuration-options","title":"Configuration Options","text":""},{"location":"tutorials/gcp-cloud-run/#mlflow-with-postgresql","title":"MLflow with PostgreSQL","text":"<pre><code>stack:\n  - experiment_tracking:\n      name: mlflow\n      params:\n        backend_store_uri: postgresql://user:pass@host:5432/dbname\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#custom-resource-limits","title":"Custom Resource Limits","text":"<pre><code>stack:\n  - model_serving:\n      name: fastapi\n      params:\n        memory: 2Gi\n        cpu: 1000m\n        max_instances: 10\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#auto-teardown","title":"Auto-Teardown","text":"<pre><code>teardown:\n  enabled: true\n  duration_hours: 24\n  time_zone: UTC\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#cost-management","title":"Cost Management","text":"<pre><code># Enable cost analysis (default)\ndeployml deploy --config-path config.yaml\n\n# Review costs before deploying\n# deployml will show estimated monthly costs\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#testing","title":"Testing","text":"<pre><code># Test MLflow health\ncurl https://mlflow-server-xxxxx-uw.a.run.app/health\n\n# Test FastAPI health\ncurl https://fastapi-server-xxxxx-uw.a.run.app/health\n\n# Test prediction endpoint\ncurl -X POST \"https://fastapi-server-xxxxx-uw.a.run.app/predict\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"features\": {...}}'\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#cleanup","title":"Cleanup","text":"<pre><code># Destroy infrastructure\ndeployml destroy --config-path cloud-run-config.yaml\n\n# Clean workspace\ndeployml destroy --config-path cloud-run-config.yaml --clean-workspace\n</code></pre>"},{"location":"tutorials/gcp-cloud-run/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/gcp-cloud-run/#service-not-starting","title":"Service Not Starting","text":"<pre><code># Check service logs\ngcloud run services logs read SERVICE_NAME --region REGION\n\n# Check service status\ngcloud run services describe SERVICE_NAME --region REGION\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/","title":"GCP Cloud VM Deployment","text":"<p>Deploy MLflow to Google Cloud VM using deployml.</p>"},{"location":"tutorials/gcp-cloud-vm/#overview","title":"Overview","text":"<p>Cloud VM deployment provides persistent storage and full control over your infrastructure. It's ideal for:</p> <ul> <li>Persistent storage</li> <li>Full control</li> <li>Cost-effective for long-running services</li> <li>Custom configurations</li> </ul>"},{"location":"tutorials/gcp-cloud-vm/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/gcp-cloud-vm/#1-create-configuration-file","title":"1. Create Configuration File","text":"<p>Create <code>cloud-vm-config.yaml</code>:</p> <pre><code>name: mlflow-cloud-vm\nprovider:\n  name: gcp\n  project_id: YOUR_PROJECT_ID\n  region: us-west1\n  zone: us-west1-a\n\ndeployment:\n  type: cloud_vm\n\nstack:\n  - experiment_tracking:\n      name: mlflow\n      params:\n        vm_name: mlflow-vm\n        machine_type: e2-medium\n        disk_size_gb: 20\n        mlflow_port: 5000\n        backend_store_uri: sqlite:///mlflow.db\n\n  - artifact_tracking:\n      name: mlflow\n      params:\n        artifact_bucket: mlflow-artifacts-bucket\n        create_artifact_bucket: true\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#2-initialize-gcp-project","title":"2. Initialize GCP Project","text":"<pre><code># Initialize GCP project (first time only)\ndeployml init --provider gcp --project-id YOUR_PROJECT_ID\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#3-deploy","title":"3. Deploy","text":"<pre><code># Deploy stack\ndeployml deploy --config-path cloud-vm-config.yaml\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#4-access-vm","title":"4. Access VM","text":"<p>After deployment, you'll get the VM's external IP address. Access MLflow via:</p> <pre><code>http://VM_EXTERNAL_IP:5000\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#configuration-options","title":"Configuration Options","text":""},{"location":"tutorials/gcp-cloud-vm/#custom-machine-type","title":"Custom Machine Type","text":"<pre><code>stack:\n  - experiment_tracking:\n      name: mlflow\n      params:\n        machine_type: e2-standard-4  # 4 vCPU, 16GB RAM\n        disk_size_gb: 50\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#postgresql-backend","title":"PostgreSQL Backend","text":"<pre><code>stack:\n  - experiment_tracking:\n      name: mlflow\n      params:\n        backend_store_uri: postgresql://user:pass@host:5432/dbname\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#ssh-access","title":"SSH Access","text":"<pre><code># SSH into VM\ngcloud compute ssh mlflow-vm --zone us-west1-a\n\n# Check MLflow status\nsudo systemctl status mlflow\n\n# View MLflow logs\nsudo journalctl -u mlflow -f\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#cleanup","title":"Cleanup","text":"<pre><code># Destroy infrastructure\ndeployml destroy --config-path cloud-vm-config.yaml\n\n# Clean workspace\ndeployml destroy --config-path cloud-vm-config.yaml --clean-workspace\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/gcp-cloud-vm/#vm-not-accessible","title":"VM Not Accessible","text":"<pre><code># Check VM status\ngcloud compute instances describe mlflow-vm --zone us-west1-a\n\n# Check firewall rules\ngcloud compute firewall-rules list --filter=\"name~mlflow\"\n</code></pre>"},{"location":"tutorials/gcp-cloud-vm/#mlflow-not-running","title":"MLflow Not Running","text":"<pre><code># SSH into VM\ngcloud compute ssh mlflow-vm --zone us-west1-a\n\n# Check service status\nsudo systemctl status mlflow\n\n# Restart service\nsudo systemctl restart mlflow\n</code></pre>"},{"location":"tutorials/gcp/","title":"GCP Deployment Guide","text":"<p>DeployML supports multiple deployment types on Google Cloud Platform.</p>"},{"location":"tutorials/gcp/#deployment-types","title":"Deployment Types","text":""},{"location":"tutorials/gcp/#cloud-run-serverless","title":"Cloud Run (Serverless)","text":"<p>Serverless container deployment for MLflow and FastAPI services.</p> <p>Features: - Automatic scaling - Pay per use - No infrastructure management</p> <p>Get Started \u2192</p>"},{"location":"tutorials/gcp/#gke-google-kubernetes-engine","title":"GKE (Google Kubernetes Engine)","text":"<p>Kubernetes-based deployment for production workloads.</p> <p>Features: - Production-ready - Full control - Custom configurations - Two-step workflow (generate manifests, then apply)</p> <p>Get Started \u2192</p>"},{"location":"tutorials/gcp/#cloud-vm","title":"Cloud VM","text":"<p>Virtual machine deployment for MLflow and other services.</p> <p>Features: - Persistent storage - Full control - Cost-effective for long-running services</p> <p>Get Started \u2192</p>"},{"location":"tutorials/gcp/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Install deployml <pre><code>pip install deployml-core\n</code></pre></p> </li> <li> <p>Initialize GCP project <pre><code>deployml init --provider gcp --project-id YOUR_PROJECT_ID\n</code></pre></p> </li> <li> <p>Choose your deployment type</p> </li> <li>Cloud Run - Serverless, auto-scaling</li> <li>GKE - Kubernetes, production-ready</li> <li> <p>Cloud VM - Persistent storage, full control</p> </li> <li> <p>Deploy <pre><code>deployml deploy --config-path your-config.yaml\n</code></pre></p> </li> </ol>"},{"location":"tutorials/gcp/#comparison","title":"Comparison","text":"Feature Cloud Run GKE Cloud VM Scaling Automatic Manual Manual Cost Pay per use Per node Per VM Best For Production APIs Production workloads Long-running services Setup Time Fast Medium Medium"},{"location":"tutorials/gke-deployment/","title":"GKE Deployment Guide","text":"<p>Complete guide for deploying MLflow and FastAPI to Google Kubernetes Engine (GKE) using deployml.</p>"},{"location":"tutorials/gke-deployment/#overview","title":"Overview","text":"<p>GKE deployment uses Kubernetes manifests (similar to minikube) and automatically pushes Docker images to Google Container Registry (GCR).</p>"},{"location":"tutorials/gke-deployment/#prerequisites","title":"Prerequisites","text":""},{"location":"tutorials/gke-deployment/#required-software","title":"Required Software","text":"<pre><code># Verify installations\ngcloud --version\nkubectl version --client\ndocker --version\ndeployml --version\n</code></pre>"},{"location":"tutorials/gke-deployment/#gcp-setup","title":"GCP Setup","text":"<pre><code># Authenticate with GCP\ngcloud auth login\ngcloud auth application-default login\n\n# Set your project\ngcloud config set project YOUR_PROJECT_ID\n\n# Enable required APIs\ndeployml init --provider gcp --project-id YOUR_PROJECT_ID\n</code></pre>"},{"location":"tutorials/gke-deployment/#gke-cluster-setup","title":"GKE Cluster Setup","text":""},{"location":"tutorials/gke-deployment/#create-a-new-cluster","title":"Create a New Cluster","text":"<pre><code>gcloud container clusters create my-gke-cluster \\\n  --zone us-west1-a \\\n  --num-nodes 2 \\\n  --machine-type e2-medium \\\n  --project YOUR_PROJECT_ID\n</code></pre>"},{"location":"tutorials/gke-deployment/#use-existing-cluster","title":"Use Existing Cluster","text":"<pre><code># List existing clusters\ngcloud container clusters list --project YOUR_PROJECT_ID\n</code></pre> <p>Note: If you have an existing company kubeconfig: - No manual setup needed - <code>deployml deploy</code> handles everything automatically - Your company kubeconfig is safe - <code>gcloud get-credentials</code> adds a new context, it doesn't delete existing ones - Context switching - After deployment, kubectl will point to the GKE cluster. To switch back:   <pre><code>kubectl config use-context YOUR_COMPANY_CONTEXT_NAME\n</code></pre></p>"},{"location":"tutorials/gke-deployment/#cluster-sizing-recommendations","title":"Cluster Sizing Recommendations","text":"Workload Nodes Machine Type Total CPU Total RAM Small (MLflow only) 1 e2-medium 2 vCPU 4GB Medium (MLflow + FastAPI) 2 e2-medium 4 vCPU 8GB Large (Production) 3+ e2-standard-4 12+ vCPU 16+ GB"},{"location":"tutorials/gke-deployment/#build-and-push-docker-images","title":"Build and Push Docker Images","text":""},{"location":"tutorials/gke-deployment/#build-mlflow-image","title":"Build MLflow Image","text":"<pre><code>cd demo/mlflow\ndocker build --platform linux/amd64 -t mlflow-demo:latest .\ncd ../..\n</code></pre>"},{"location":"tutorials/gke-deployment/#build-fastapi-image","title":"Build FastAPI Image","text":"<pre><code>cd demo/fastapi\ndocker build --platform linux/amd64 -t fastapi-mlflow-demo:latest .\ncd ../..\n</code></pre> <p>Note: The <code>deployml deploy</code> command will automatically push images if they're local, but you can also push manually.</p>"},{"location":"tutorials/gke-deployment/#configuration-file","title":"Configuration File","text":"<p>Create <code>gke-config.yaml</code>:</p> <pre><code>name: gke-mlflow-fastapi\nprovider:\n  name: gcp\n  project_id: YOUR_PROJECT_ID\n  region: us-west1\n\ndeployment:\n  type: gke\n\ngke:\n  cluster_name: my-gke-cluster\n  zone: us-west1-a  # For zonal cluster\n  # OR use region for regional cluster:\n  # region: us-west1\n\nstack:\n  - experiment_tracking:\n      name: mlflow\n      params:\n        image: mlflow-demo:latest  # Local image name (will be pushed to GCR)\n        backend_store_uri: sqlite:///mlflow.db\n\n  - artifact_tracking:\n      name: mlflow\n      params:\n        artifact_bucket: mlflow-artifacts-bucket\n        create_artifact_bucket: true\n\n  - model_registry:\n      name: mlflow\n      params:\n        backend_store_uri: sqlite:///mlflow.db\n\n  - model_serving:\n      name: fastapi\n      params:\n        image: fastapi-mlflow-demo:latest\n        mlflow_tracking_uri: http://mlflow-service:5000\n</code></pre>"},{"location":"tutorials/gke-deployment/#key-configuration-points","title":"Key Configuration Points","text":"<ul> <li><code>deployment.type: gke</code> - Tells deployml to use Kubernetes manifests</li> <li><code>gke.cluster_name</code> - Your GKE cluster name</li> <li><code>gke.zone</code> - Cluster zone (or use <code>region</code> for regional clusters)</li> <li><code>image</code> - Local Docker image name (will be converted to GCR format)</li> <li><code>mlflow_tracking_uri</code> - Use <code>http://mlflow-service:5000</code> (Kubernetes internal DNS)</li> </ul>"},{"location":"tutorials/gke-deployment/#deployment-workflows","title":"Deployment Workflows","text":""},{"location":"tutorials/gke-deployment/#option-1-generate-and-deploy-in-one-step","title":"Option 1: Generate and Deploy in One Step","text":"<pre><code># Deploy everything (generates manifests and applies them)\ndeployml deploy -c gke-config.yaml\n\n# This will:\n# 1. Connect to GKE cluster\n# 2. Generate Kubernetes manifests\n# 3. Push images to GCR (if local)\n# 4. Deploy to GKE\n# 5. Show LoadBalancer URLs\n</code></pre>"},{"location":"tutorials/gke-deployment/#option-2-two-step-workflow-generate-review-apply","title":"Option 2: Two-Step Workflow (Generate, Review &amp; Apply)","text":"<p>Step 1: Generate Manifests Only</p> <pre><code># Generate manifests without applying\ndeployml deploy -c gke-config.yaml --generate-only\n\n# Manifests are saved to:\n# .deployml/&lt;workspace&gt;/manifests/mlflow/deployment.yaml\n# .deployml/&lt;workspace&gt;/manifests/mlflow/service.yaml\n# .deployml/&lt;workspace&gt;/manifests/fastapi/deployment.yaml\n# .deployml/&lt;workspace&gt;/manifests/fastapi/service.yaml\n</code></pre> <p>Step 2: Review and Edit Manifests (Optional)</p> <pre><code># Edit manifests if needed (e.g., adjust resource limits)\nnano .deployml/gke-mlflow-fastapi/manifests/mlflow/deployment.yaml\n\n# Common edits:\n# - Adjust CPU/memory requests/limits\n# - Change replica count\n# - Modify environment variables\n</code></pre> <p>Step 3: Apply Manifests</p> <pre><code># Apply manifests to GKE cluster\ndeployml gke-apply -c gke-config.yaml\n\n# Or apply manually:\nkubectl apply -f .deployml/gke-mlflow-fastapi/manifests/mlflow/\nkubectl apply -f .deployml/gke-mlflow-fastapi/manifests/fastapi/\n</code></pre> <p>Benefits of Two-Step Workflow: - Review manifests before deployment - Edit resource limits, replicas, or environment variables - Version control manifests - Apply changes incrementally - Debug issues before deployment</p>"},{"location":"tutorials/gke-deployment/#verify-deployment","title":"Verify Deployment","text":"<pre><code># Check pods\nkubectl get pods -l app=mlflow\nkubectl get pods -l app=fastapi\n\n# Check services\nkubectl get svc mlflow-service\nkubectl get svc fastapi-service\n\n# Get LoadBalancer IPs\nMLFLOW_IP=$(kubectl get svc mlflow-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\nFASTAPI_IP=$(kubectl get svc fastapi-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\necho \"MLflow URL: http://$MLFLOW_IP:5000\"\necho \"FastAPI URL: http://$FASTAPI_IP:8000\"\n</code></pre>"},{"location":"tutorials/gke-deployment/#testing","title":"Testing","text":"<pre><code># Test MLflow health\ncurl http://$MLFLOW_IP:5000/health\n\n# Test FastAPI health\ncurl http://$FASTAPI_IP:8000/health\n\n# View logs\nkubectl logs -l app=mlflow --tail=50 -f\nkubectl logs -l app=fastapi --tail=50 -f\n</code></pre>"},{"location":"tutorials/gke-deployment/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/gke-deployment/#pod-stuck-in-pending","title":"Pod Stuck in Pending","text":"<pre><code># Check pod status\nkubectl describe pod POD_NAME\n\n# Common fixes:\n# 1. Reduce resource requests\nkubectl patch deployment mlflow-deployment -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"mlflow\",\"resources\":{\"requests\":{\"cpu\":\"100m\",\"memory\":\"256Mi\"}}}]}}}}'\n\n# 2. Scale up cluster\ngcloud container clusters resize CLUSTER_NAME --num-nodes 3 --zone ZONE\n</code></pre>"},{"location":"tutorials/gke-deployment/#image-pull-errors","title":"Image Pull Errors","text":"<pre><code># Verify image exists in GCR\ngcloud container images list-tags gcr.io/PROJECT_ID/mlflow/mlflow --project=PROJECT_ID\n\n# Push image manually if needed\ndocker tag mlflow-demo:latest gcr.io/PROJECT_ID/mlflow/mlflow:latest\ndocker push gcr.io/PROJECT_ID/mlflow/mlflow:latest\n</code></pre>"},{"location":"tutorials/gke-deployment/#resource-management","title":"Resource Management","text":""},{"location":"tutorials/gke-deployment/#check-current-resource-usage","title":"Check Current Resource Usage","text":"<pre><code>kubectl top nodes\nkubectl top pods\nkubectl describe nodes\n</code></pre>"},{"location":"tutorials/gke-deployment/#reduce-resource-requests","title":"Reduce Resource Requests","text":"<pre><code># Edit deployment\nkubectl edit deployment DEPLOYMENT_NAME\n\n# Or patch deployment\nkubectl patch deployment DEPLOYMENT_NAME -p '{\"spec\":{\"template\":{\"spec\":{\"containers\":[{\"name\":\"CONTAINER_NAME\",\"resources\":{\"requests\":{\"cpu\":\"100m\",\"memory\":\"256Mi\"}}}]}}}}'\n</code></pre>"},{"location":"tutorials/gke-deployment/#recommended-resource-settings","title":"Recommended Resource Settings","text":"<p>For Small Clusters (2 nodes \u00d7 e2-medium):</p> <pre><code># MLflow\nresources:\n  requests:\n    cpu: \"250m\"\n    memory: \"512Mi\"\n  limits:\n    cpu: \"1000m\"\n    memory: \"2Gi\"\n\n# FastAPI\nresources:\n  requests:\n    cpu: \"100m\"\n    memory: \"256Mi\"\n  limits:\n    cpu: \"500m\"\n    memory: \"1Gi\"\n</code></pre>"},{"location":"tutorials/gke-deployment/#cleanup","title":"Cleanup","text":"<pre><code># Delete deployments\nkubectl delete deployment mlflow-deployment fastapi-deployment\n\n# Delete services\nkubectl delete service mlflow-service fastapi-service\n\n# Delete cluster (optional)\ngcloud container clusters delete CLUSTER_NAME --zone ZONE\n</code></pre>"},{"location":"tutorials/gke-deployment/#quick-reference","title":"Quick Reference","text":"<pre><code># Get service URLs\nMLFLOW_IP=$(kubectl get svc mlflow-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\nFASTAPI_IP=$(kubectl get svc fastapi-service -o jsonpath='{.status.loadBalancer.ingress[0].ip}')\n\n# Check pods\nkubectl get pods -l app=mlflow\nkubectl get pods -l app=fastapi\n\n# View logs\nkubectl logs -l app=mlflow --tail=50 -f\nkubectl logs -l app=fastapi --tail=50 -f\n</code></pre>"},{"location":"tutorials/minikube/","title":"Minikube Local Deployment","text":"<p>Deploy MLflow and FastAPI locally using Minikube for testing and development.</p>"},{"location":"tutorials/minikube/#overview","title":"Overview","text":"<p>Minikube provides a local Kubernetes environment for testing and development. It's ideal for:</p> <ul> <li>Local testing</li> <li>No cloud costs</li> <li>Fast iteration</li> <li>Learning Kubernetes</li> </ul>"},{"location":"tutorials/minikube/#prerequisites","title":"Prerequisites","text":"<pre><code># Install minikube\n# macOS\nbrew install minikube\n\n# Linux\ncurl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64\nsudo install minikube-linux-amd64 /usr/local/bin/minikube\n\n# Verify installation\nminikube version\n</code></pre>"},{"location":"tutorials/minikube/#quick-start","title":"Quick Start","text":""},{"location":"tutorials/minikube/#1-initialize-minikube-for-mlflow","title":"1. Initialize Minikube for MLflow","text":"<pre><code># Generate MLflow manifests\ndeployml mlflow-init \\\n  --output-dir ./manifests/mlflow \\\n  --image mlflow-demo:latest \\\n  --backend-store-uri sqlite:///mlflow.db\n\n# Deploy MLflow\ndeployml mlflow-deploy --manifest-dir ./manifests/mlflow\n</code></pre>"},{"location":"tutorials/minikube/#2-initialize-minikube-for-fastapi","title":"2. Initialize Minikube for FastAPI","text":"<pre><code># Generate FastAPI manifests\ndeployml minikube-init \\\n  --output-dir ./manifests/fastapi \\\n  --image fastapi-mlflow-demo:latest \\\n  --mlflow-uri http://mlflow-service:5000\n\n# Deploy FastAPI\ndeployml minikube-deploy --manifest-dir ./manifests/fastapi\n</code></pre>"},{"location":"tutorials/minikube/#3-access-services","title":"3. Access Services","text":"<pre><code># Get service URLs\nminikube service mlflow-service --url\nminikube service fastapi-service --url\n\n# Or open in browser\nminikube service mlflow-service\nminikube service fastapi-service\n</code></pre>"},{"location":"tutorials/minikube/#two-step-workflow","title":"Two-Step Workflow","text":""},{"location":"tutorials/minikube/#step-1-generate-manifests","title":"Step 1: Generate Manifests","text":"<pre><code># MLflow\ndeployml mlflow-init \\\n  --output-dir ./manifests/mlflow \\\n  --image mlflow-demo:latest \\\n  --backend-store-uri sqlite:///mlflow.db\n\n# FastAPI\ndeployml minikube-init \\\n  --output-dir ./manifests/fastapi \\\n  --image fastapi-mlflow-demo:latest \\\n  --mlflow-uri http://mlflow-service:5000\n</code></pre>"},{"location":"tutorials/minikube/#step-2-edit-manifests-optional","title":"Step 2: Edit Manifests (Optional)","text":"<pre><code># Edit deployment.yaml to adjust resources\nnano ./manifests/mlflow/deployment.yaml\n\n# Common edits:\n# - Adjust CPU/memory requests/limits\n# - Change replica count\n# - Modify environment variables\n</code></pre>"},{"location":"tutorials/minikube/#step-3-deploy","title":"Step 3: Deploy","text":"<pre><code># Deploy MLflow\ndeployml mlflow-deploy --manifest-dir ./manifests/mlflow\n\n# Deploy FastAPI\ndeployml minikube-deploy --manifest-dir ./manifests/fastapi\n</code></pre>"},{"location":"tutorials/minikube/#verify-deployment","title":"Verify Deployment","text":"<pre><code># Check pods\nkubectl get pods\n\n# Check services\nkubectl get svc\n\n# View logs\nkubectl logs -l app=mlflow --tail=50 -f\nkubectl logs -l app=fastapi --tail=50 -f\n</code></pre>"},{"location":"tutorials/minikube/#testing","title":"Testing","text":"<pre><code># Get MLflow URL\nMLFLOW_URL=$(minikube service mlflow-service --url)\n\n# Test health endpoint\ncurl $MLFLOW_URL/health\n\n# Get FastAPI URL\nFASTAPI_URL=$(minikube service fastapi-service --url)\n\n# Test health endpoint\ncurl $FASTAPI_URL/health\n</code></pre>"},{"location":"tutorials/minikube/#cleanup","title":"Cleanup","text":"<pre><code># Delete deployments\nkubectl delete deployment mlflow-deployment fastapi-deployment\n\n# Delete services\nkubectl delete service mlflow-service fastapi-service\n\n# Stop minikube\nminikube stop\n\n# Delete minikube cluster\nminikube delete\n</code></pre>"},{"location":"tutorials/minikube/#troubleshooting","title":"Troubleshooting","text":""},{"location":"tutorials/minikube/#pod-not-starting","title":"Pod Not Starting","text":"<pre><code># Check pod status\nkubectl get pods\nkubectl describe pod POD_NAME\n\n# Check logs\nkubectl logs POD_NAME\n</code></pre>"},{"location":"tutorials/minikube/#image-not-found","title":"Image Not Found","text":"<pre><code># Load image into minikube\nminikube image load mlflow-demo:latest\nminikube image load fastapi-mlflow-demo:latest\n\n# Or use minikube's Docker daemon\neval $(minikube docker-env)\ndocker build -t mlflow-demo:latest .\n</code></pre>"},{"location":"tutorials/minikube/#service-not-accessible","title":"Service Not Accessible","text":"<pre><code># Check service status\nkubectl get svc\n\n# Use minikube service command\nminikube service SERVICE_NAME --url\n</code></pre>"},{"location":"tutorials/overview/","title":"Tutorials Overview","text":"<p>Learn how to deploy MLflow and FastAPI using deployml.</p>"},{"location":"tutorials/overview/#deployment-options","title":"Deployment Options","text":""},{"location":"tutorials/overview/#cloud-run-serverless","title":"Cloud Run (Serverless)","text":"<ul> <li>Automatic scaling</li> <li>Pay per use</li> <li>No infrastructure management</li> <li>Get Started \u2192</li> </ul>"},{"location":"tutorials/overview/#gke-kubernetes","title":"GKE (Kubernetes)","text":"<ul> <li>Production-ready</li> <li>Full control</li> <li>Custom configurations</li> <li>Get Started \u2192</li> </ul>"},{"location":"tutorials/overview/#cloud-vm","title":"Cloud VM","text":"<ul> <li>Persistent storage</li> <li>Full control</li> <li>Cost-effective for long-running services</li> <li>Get Started \u2192</li> </ul>"},{"location":"tutorials/overview/#minikube-local","title":"Minikube (Local)","text":"<ul> <li>Local testing</li> <li>No cloud costs</li> <li>Fast iteration</li> <li>Get Started \u2192</li> </ul>"},{"location":"tutorials/overview/#quick-start","title":"Quick Start","text":"<ol> <li> <p>Install deployml <pre><code>pip install deployml-core\n</code></pre></p> </li> <li> <p>Initialize your cloud project <pre><code>deployml init --provider gcp --project-id YOUR_PROJECT_ID\n</code></pre></p> </li> <li> <p>Generate a config <pre><code>deployml generate\n</code></pre></p> </li> <li> <p>Deploy <pre><code>deployml deploy --config-path your-config.yaml\n</code></pre></p> </li> </ol>"},{"location":"tutorials/overview/#choose-your-deployment-type","title":"Choose Your Deployment Type","text":"Feature Cloud Run GKE Cloud VM Minikube Scaling Automatic Manual Manual N/A Cost Pay per use Per node Per VM Free Best For Production APIs Production workloads Long-running services Development"},{"location":"tutorials/overview/#next-steps","title":"Next Steps","text":"<ul> <li>Read the Installation Guide</li> <li>Explore CLI Commands</li> </ul>"}]}